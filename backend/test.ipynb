{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bcd4fa8-0dc9-4567-9c5f-f28379466a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "def order_points(pts):\n",
    "    '''Rearrange coordinates to order:\n",
    "      top-left, top-right, bottom-right, bottom-left'''\n",
    "    rect = np.zeros((4, 2), dtype='float32')\n",
    "    pts = np.array(pts)\n",
    "    s = pts.sum(axis=1)\n",
    "    # Top-left point will have the smallest sum.\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    # Bottom-right point will have the largest sum.\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    diff = np.diff(pts, axis=1)\n",
    "    # Top-right point will have the smallest difference.\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    # Bottom-left will have the largest difference.\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    # return the ordered coordinates\n",
    "    return rect.astype('int').tolist()\n",
    "\n",
    "def find_dest(pts):\n",
    "    (tl, tr, br, bl) = pts\n",
    "    # Finding the maximum width.\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # Finding the maximum height.\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "    # Final destination co-ordinates.\n",
    "    destination_corners = [[0, 0], [maxWidth, 0], [maxWidth, maxHeight], [0, maxHeight]]\n",
    "\n",
    "    return order_points(destination_corners)\n",
    "\n",
    "def scan(img_path):\n",
    "    # Resize image to workable size\n",
    "    # dim_limit = 1080    \n",
    "    img = cv2.imread(img_path, 1)    \n",
    "    max_dim = max(img.shape)\n",
    "    # if max_dim > dim_limit:\n",
    "        # resize_scale = dim_limit / max_dim\n",
    "        # img = cv2.resize(img, None, fx=resize_scale, fy=resize_scale)\n",
    "    # Create a copy of resized original image for later use\n",
    "    orig_img = img.copy()\n",
    "    # Repeated Closing operation to remove text from the document.\n",
    "    kernel = np.ones((5, 5), np.uint8)\n",
    "    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "    # GrabCut\n",
    "    mask = np.zeros(img.shape[:2], np.uint8)\n",
    "    bgdModel = np.zeros((1, 65), np.float64)\n",
    "    fgdModel = np.zeros((1, 65), np.float64)\n",
    "    rect = (20, 20, img.shape[1] - 20, img.shape[0] - 20)\n",
    "    cv2.grabCut(img, mask, rect, bgdModel, fgdModel, 5, cv2.GC_INIT_WITH_RECT)\n",
    "    mask2 = np.where((mask == 2) | (mask == 0), 0, 1).astype('uint8')\n",
    "    img = img * mask2[:, :, np.newaxis]\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.GaussianBlur(gray, (11, 11), 0)\n",
    "    # Edge Detection.\n",
    "    canny = cv2.Canny(gray, 0, 200)\n",
    "    canny = cv2.dilate(canny, cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5)))\n",
    "\n",
    "    # Finding contours for the detected edges.\n",
    "    contours, hierarchy = cv2.findContours(canny, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
    "    # Keeping only the largest detected contour.\n",
    "    page = sorted(contours, key=cv2.contourArea, reverse=True)[:5]\n",
    "\n",
    "    # Detecting Edges through Contour approximation.\n",
    "    # Loop over the contours.\n",
    "    if len(page) == 0:\n",
    "        return orig_img\n",
    "    for c in page:\n",
    "        # Approximate the contour.\n",
    "        epsilon = 0.02 * cv2.arcLength(c, True)\n",
    "        corners = cv2.approxPolyDP(c, epsilon, True)\n",
    "        # If our approximated contour has four points.\n",
    "        if len(corners) == 4:\n",
    "            break\n",
    "    # Sorting the corners and converting them to desired shape.\n",
    "    corners = sorted(np.concatenate(corners).tolist())\n",
    "    # For 4 corner points being detected.\n",
    "    corners = order_points(corners)\n",
    "\n",
    "    destination_corners = find_dest(corners)\n",
    "\n",
    "    h, w = orig_img.shape[:2]\n",
    "    # Getting the homography.\n",
    "    M = cv2.getPerspectiveTransform(np.float32(corners), np.float32(destination_corners))\n",
    "    # Perspective transform using homography.\n",
    "    final = cv2.warpPerspective(orig_img, M, (destination_corners[2][0], destination_corners[2][1]),\n",
    "                                flags=cv2.INTER_LINEAR)\n",
    "    return final\n",
    "\n",
    "def get_image_download_link(img, filename, text):\n",
    "    buffered = io.BytesIO()\n",
    "    img.save(buffered, format='JPEG')\n",
    "    img_str = base64.b64encode(buffered.getvalue()).decode()\n",
    "    href = f'<a href=\"data:file/txt;base64,{img_str}\" download=\"{filename}\">{text}</a>'\n",
    "    return href\n",
    "\n",
    "image = scan(\"/home/ailab/AICoffee/backend/BigBroken_20201015_723338_000-005_3,80g_122.jpg\")\n",
    "cv2.imwrite('test.jpg', image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a416d-605e-48a6-a7ec-a965b5230269",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coffee_env",
   "language": "python",
   "name": "coffee_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
